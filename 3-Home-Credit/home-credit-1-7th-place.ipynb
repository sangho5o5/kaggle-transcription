{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T11:16:12.703324Z","iopub.execute_input":"2021-11-20T11:16:12.704174Z","iopub.status.idle":"2021-11-20T11:16:12.748184Z","shell.execute_reply.started":"2021-11-20T11:16:12.704038Z","shell.execute_reply":"2021-11-20T11:16:12.747508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 필사 대상 노트북 원본\nhttps://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution\n# 대회 주제\n고객의 대출상환 능력을 가늠하자\n\n# 평가지표\nArea under the ROC curve\n\n# 목표\nTARGET 이라는 변수에 상환 확률을 주어야 한다.","metadata":{}},{"cell_type":"code","source":"import os\nimport gc # 나중에 메모리 관리 해야 함\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:12.749744Z","iopub.execute_input":"2021-11-20T11:16:12.750187Z","iopub.status.idle":"2021-11-20T11:16:15.025569Z","shell.execute_reply.started":"2021-11-20T11:16:12.750154Z","shell.execute_reply":"2021-11-20T11:16:15.024632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 진행방식\n기존 코드가 함수형으로 되어 있어서 진행 순서대로 풀어서 다시 쓴다.","metadata":{}},{"cell_type":"code","source":"# main 상단에 있던 일반 전역변수들\n# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"../input/\"\nSUBMISSION_SUFIX = \"_model2_04\"","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.026858Z","iopub.execute_input":"2021-11-20T11:16:15.027096Z","iopub.status.idle":"2021-11-20T11:16:15.03168Z","shell.execute_reply.started":"2021-11-20T11:16:15.027066Z","shell.execute_reply":"2021-11-20T11:16:15.030725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 출력 크기 제한\npd.set_option('display.max_rows', 60)\npd.set_option('display.max_columns', 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.034309Z","iopub.execute_input":"2021-11-20T11:16:15.034737Z","iopub.status.idle":"2021-11-20T11:16:15.043988Z","shell.execute_reply.started":"2021-11-20T11:16:15.034693Z","shell.execute_reply":"2021-11-20T11:16:15.043098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 기본적으로 debug=False였지만 main함수 실행조건이 debug=True라서 True로 변환해서 쭉 사용한다\ndebug = True","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.045267Z","iopub.execute_input":"2021-11-20T11:16:15.045935Z","iopub.status.idle":"2021-11-20T11:16:15.058022Z","shell.execute_reply.started":"2021-11-20T11:16:15.045892Z","shell.execute_reply":"2021-11-20T11:16:15.057073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 갯수 제한 하기 위함  \nnum_rows = 30000 if debug else None ","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.059525Z","iopub.execute_input":"2021-11-20T11:16:15.05983Z","iopub.status.idle":"2021-11-20T11:16:15.069873Z","shell.execute_reply.started":"2021-11-20T11:16:15.059787Z","shell.execute_reply":"2021-11-20T11:16:15.068952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 이제 아래 코드를 사용해야 하지만 get_train_test 메소드는 풀어서 사용하기 때문에 주석처리함\n# df = get_train_test(DATA_DIRECTORY, num_rows= num_rows)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.071648Z","iopub.execute_input":"2021-11-20T11:16:15.072236Z","iopub.status.idle":"2021-11-20T11:16:15.084536Z","shell.execute_reply.started":"2021-11-20T11:16:15.072188Z","shell.execute_reply":"2021-11-20T11:16:15.083662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_THREADS = 4\nDATA_DIRECTORY = '../input/home-credit-default-risk/'\nSUBMISSION_SUFIX = '_model2_04'","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.086008Z","iopub.execute_input":"2021-11-20T11:16:15.086336Z","iopub.status.idle":"2021-11-20T11:16:15.100527Z","shell.execute_reply.started":"2021-11-20T11:16:15.086294Z","shell.execute_reply":"2021-11-20T11:16:15.099856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = DATA_DIRECTORY\nnum_rows = num_rows","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.102082Z","iopub.execute_input":"2021-11-20T11:16:15.102602Z","iopub.status.idle":"2021-11-20T11:16:15.114004Z","shell.execute_reply.started":"2021-11-20T11:16:15.102549Z","shell.execute_reply":"2021-11-20T11:16:15.11314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows= num_rows)\ntest = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows= num_rows)\ndf = train.append(test) # train,test 합친다\n# train,test각각 데이터 3만개가 있으면 된다\nprint(train.info())\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:15.116897Z","iopub.execute_input":"2021-11-20T11:16:15.11722Z","iopub.status.idle":"2021-11-20T11:16:16.4305Z","shell.execute_reply.started":"2021-11-20T11:16:15.117172Z","shell.execute_reply":"2021-11-20T11:16:16.429511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 타겟 컬럼의 imbalance를 확인하기 위함\n# 1이 상당히 적다는걸 인지하고 진행\ntrain['TARGET'].value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.431764Z","iopub.execute_input":"2021-11-20T11:16:16.431998Z","iopub.status.idle":"2021-11-20T11:16:16.672409Z","shell.execute_reply.started":"2021-11-20T11:16:16.43197Z","shell.execute_reply":"2021-11-20T11:16:16.67147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 사용하지 않는 메모리 회수\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.67386Z","iopub.execute_input":"2021-11-20T11:16:16.674116Z","iopub.status.idle":"2021-11-20T11:16:16.80034Z","shell.execute_reply.started":"2021-11-20T11:16:16.674085Z","shell.execute_reply":"2021-11-20T11:16:16.799747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n주로 대출 상환 능력을 평가하기위한 피쳐를 만든다","metadata":{}},{"cell_type":"code","source":"# Data Cleansing\n# 전체 데이터에서 CODE_GENDER 피쳐에서 XNA가 있는 데이터는 4개 뿐이라 제거\ndf = df[df['CODE_GENDER'] != 'XNA']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.801495Z","iopub.execute_input":"2021-11-20T11:16:16.801862Z","iopub.status.idle":"2021-11-20T11:16:16.905916Z","shell.execute_reply.started":"2021-11-20T11:16:16.801833Z","shell.execute_reply":"2021-11-20T11:16:16.90489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 사용할 데이터셋의 사람들의 수입에 제한에 두기 위해\ndf = df[df['AMT_INCOME_TOTAL'] < 20000000]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.907307Z","iopub.execute_input":"2021-11-20T11:16:16.907834Z","iopub.status.idle":"2021-11-20T11:16:16.940247Z","shell.execute_reply.started":"2021-11-20T11:16:16.907787Z","shell.execute_reply":"2021-11-20T11:16:16.939384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DAYS_EMPLOYED 사람들의 고용된 날짜\n# 해당 피쳐에서 이상값으로 365243이 있는데 해당 값을 지우기 위해서\ndf['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.94133Z","iopub.execute_input":"2021-11-20T11:16:16.941568Z","iopub.status.idle":"2021-11-20T11:16:16.952738Z","shell.execute_reply.started":"2021-11-20T11:16:16.941542Z","shell.execute_reply":"2021-11-20T11:16:16.951899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 해드폰 교체 시기인데 0인 값들은 제거\ndf['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.954792Z","iopub.execute_input":"2021-11-20T11:16:16.955285Z","iopub.status.idle":"2021-11-20T11:16:16.961768Z","shell.execute_reply.started":"2021-11-20T11:16:16.95524Z","shell.execute_reply":"2021-11-20T11:16:16.960848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flag_document features - count and kurtosis\n# FLAG_DOC이 있는 피쳐들은 거의 binary라서 합친다\ndocs = [f for f in df.columns if 'FLAG_DOC' in f]\n# 0,1,2,3 중에 1인것들의 갯수가 월등히 많아서 1인것의 갯수\ndf['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n# kurtosis가 있는 것들을 별도 피쳐로 생성\ndf['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:16.963007Z","iopub.execute_input":"2021-11-20T11:16:16.963232Z","iopub.status.idle":"2021-11-20T11:16:17.023018Z","shell.execute_reply.started":"2021-11-20T11:16:16.963198Z","shell.execute_reply":"2021-11-20T11:16:17.022051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical age - based on target=1 plot\n# DAYS_BIRTH는 살아온 날\n# DAYS_BIRTH를 카테고리 피쳐로 만들어 AGE_RANGE로 저장해 새로운 피쳐로 생\n\ndef get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \n        나이를 나이대로 분류\n    \"\"\"\n    age_years = -days_birth / 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0\n    \ndf['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.024459Z","iopub.execute_input":"2021-11-20T11:16:17.025316Z","iopub.status.idle":"2021-11-20T11:16:17.09623Z","shell.execute_reply.started":"2021-11-20T11:16:17.025269Z","shell.execute_reply":"2021-11-20T11:16:17.095178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New features based on External sources\n# EXT_SOURCES 3가지는 항상 feature importance와 correlation에서 1,2,3등으로 나와서 묶어서 곱해 하나의 피쳐로 만든다\n# 현업의 경우 설명을 해주어야 하지만 어렵다. 하지만 캐글에선 어떻게든 성능을 올리는게 목표기 떄문에 그냥 쓴다\ndf['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n# 가중치를 주어서 합하기\n# 가중치 크기는 다른 사람들의 커널의 피쳐분석에서 항상 높은 순위로 나온대로 사용\ndf['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n# 각 수리통계 수치의 이름을 피쳐이름에 넣으면서 계산해 내기 위해 for문으로 진행\nnp.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\nfor function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n    feature_name = 'EXT_SOURCES_{}'.format(function_name.upper()) # 피쳐이름 생성\n    # 피쳐이름을 eval안의 코드에 적용해서 실행\n    df[feature_name] = eval('np.{}'.format(function_name))(\n        df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1) ","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.097971Z","iopub.execute_input":"2021-11-20T11:16:17.098315Z","iopub.status.idle":"2021-11-20T11:16:17.277512Z","shell.execute_reply.started":"2021-11-20T11:16:17.098269Z","shell.execute_reply":"2021-11-20T11:16:17.276624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Credit ratios\n# 사람의 재정상태를 평가하기 위해서 2가지 피쳐를 생성\n# 사람들의 빚과 연금간의 비율 피쳐 생성\ndf['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n# 빚과 대출 발생시의 물가 비율 피쳐 생성\ndf['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.278716Z","iopub.execute_input":"2021-11-20T11:16:17.278951Z","iopub.status.idle":"2021-11-20T11:16:17.287036Z","shell.execute_reply.started":"2021-11-20T11:16:17.278922Z","shell.execute_reply":"2021-11-20T11:16:17.286026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Income ratios\n# 연금과 수입 비율\ndf['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n# 빚과 수입 비율, 수입과 지출에 대한 평갸\ndf['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n# 수입과 노동일수 비율, 돈버는 능력 평가\ndf['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n# 나이와 수입 비율\ndf['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.289015Z","iopub.execute_input":"2021-11-20T11:16:17.289381Z","iopub.status.idle":"2021-11-20T11:16:17.307591Z","shell.execute_reply.started":"2021-11-20T11:16:17.289338Z","shell.execute_reply":"2021-11-20T11:16:17.30677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time ratios\n# 노동일수와 나이 비율\ndf['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n# 고객정보가 수정된 날짜와 나이 비율\ndf['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n# 보유차량 연식과 나이 비율\ndf['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n# 보유차량 연식과\ndf['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\ndf['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.30897Z","iopub.execute_input":"2021-11-20T11:16:17.309757Z","iopub.status.idle":"2021-11-20T11:16:17.321315Z","shell.execute_reply.started":"2021-11-20T11:16:17.309723Z","shell.execute_reply":"2021-11-20T11:16:17.320312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 영상2번","metadata":{}},{"cell_type":"code","source":"group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\ndf[group]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.323006Z","iopub.execute_input":"2021-11-20T11:16:17.323393Z","iopub.status.idle":"2021-11-20T11:16:17.376751Z","shell.execute_reply.started":"2021-11-20T11:16:17.323345Z","shell.execute_reply":"2021-11-20T11:16:17.376037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby: Statistics for applications in the same group\n# 통계 연산을 특정 피쳐들 기준으로 연산하여 새로운 피쳐를 만든다\n\n# 아래 4가지 메소드는 기본통계 연산을 하는 메소드\n# df는 데이터\n# group_cols는 선택한 피쳐목록\n# counted는 계산대상 피쳐\n# agg_name은 새로 만들어진 피쳐의 이름\ndef do_mean(df, group_cols, counted, agg_name):\n    # group_cols기즌으로 groupby후 연산\n    # reset_index로 정리 후 rename으로 기존 피쳐 이름이 counted인 것을 agg_name으로 변경\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    # df와 gp를 붙이는데 on에 지정된 피쳐들을 기준으로 왼쪽(left)에 붙인\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n# 아래 group에 명시된 피쳐들 기준으로 통계연산을 해서 새로운 피쳐를 만든다\ngroup = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\ndf = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\ndf = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\ndf = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\ndf = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\ndf = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\ndf = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\ndf = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\ndf = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\ndf = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:17.377955Z","iopub.execute_input":"2021-11-20T11:16:17.378322Z","iopub.status.idle":"2021-11-20T11:16:22.468975Z","shell.execute_reply.started":"2021-11-20T11:16:17.378291Z","shell.execute_reply":"2021-11-20T11:16:22.467921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode categorical features (LabelEncoder)\n# 카테고리 피쳐들 인코딩\ndef label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    # scikit의 라벨인코더보단 pandas.factorize가 더 빨르고 데이터가 많아서 factorize를 사용하는것 같다    \n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns\n\ndef drop_application_columns(df):\n    \"\"\" Drop features based on permutation feature importance. \"\"\"\n    # permutation feature importance에 기반해서 피쳐를 제거한다\n    drop_list = [\n        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n    ]\n    # Drop most flag document columns\n    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n    df.drop(drop_list, axis=1, inplace=True)\n    return df\n\n\ndf, le_encoded_cols = label_encoder(df, None)\ndf = drop_application_columns(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:22.470303Z","iopub.execute_input":"2021-11-20T11:16:22.471004Z","iopub.status.idle":"2021-11-20T11:16:22.664944Z","shell.execute_reply.started":"2021-11-20T11:16:22.470968Z","shell.execute_reply":"2021-11-20T11:16:22.663993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## permutaiton feature importance\n보통 feature importance는 여러번 피쳐를 바꾸어 가며 학습해 최고의 성능을 주는 피쳐를 선택한다.  \n그러나 permuation은 랜덤하게 피쳐를 선택해서 단 한번만 학습을 시킨다.\n- 모든 피쳐를 랜덤하게 섞어서 피쳐와 타겟관의 연결고리를 끊는다\n- 학습 후 예측값과 실제값의 차이를 계상해서 피쳐의 영향력을 파악한다\n- 만약 피쳐가 타겟에 영향이 크면 예측 정확도가 크게 감소하기 때문에 해당 피쳐는 중요도가 크다고 할 수 있다.\n- 랜덤하기 때문에 매번 결과가 바뀔 수 있으나 섞는 횟수를 늘려서 그나마 상쇠시킬 수 있다\n","metadata":{}},{"cell_type":"code","source":"print(\"Application dataframe shape: \", df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:22.666196Z","iopub.execute_input":"2021-11-20T11:16:22.666456Z","iopub.status.idle":"2021-11-20T11:16:22.671122Z","shell.execute_reply.started":"2021-11-20T11:16:22.666413Z","shell.execute_reply":"2021-11-20T11:16:22.67033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# bureau.csv 데이터셋 가공\n- application data from previous loans that client got from other institutions and that were reported to Credit Bureau\n- One row per client's loan in Credit Bureau","metadata":{}},{"cell_type":"code","source":"# bureau데이터 사용\n# bureau_df = get_bureau(DATA_DIRECTORY, num_rows= num_rows)\n# df = pd.merge(df, bureau_df, on='SK_ID_CURR', how='left')\n# print(\"Bureau dataframe shape: \", bureau_df.shape)\n# del bureau_df; gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:22.672488Z","iopub.execute_input":"2021-11-20T11:16:22.672913Z","iopub.status.idle":"2021-11-20T11:16:22.683499Z","shell.execute_reply.started":"2021-11-20T11:16:22.672873Z","shell.execute_reply":"2021-11-20T11:16:22.68265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# get_bureau 메소드","metadata":{}},{"cell_type":"code","source":"\"\"\" Process bureau.csv and bureau_balance.csv and return a pandas dataframe. \"\"\"\nbureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows= num_rows)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:22.687562Z","iopub.execute_input":"2021-11-20T11:16:22.687791Z","iopub.status.idle":"2021-11-20T11:16:22.788811Z","shell.execute_reply.started":"2021-11-20T11:16:22.687765Z","shell.execute_reply":"2021-11-20T11:16:22.787855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Credit duration and credit/account end date difference\nbureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\nbureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n# Credit to debt ratio and difference\nbureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\nbureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\nbureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:22.790115Z","iopub.execute_input":"2021-11-20T11:16:22.790914Z","iopub.status.idle":"2021-11-20T11:16:22.801587Z","shell.execute_reply.started":"2021-11-20T11:16:22.790865Z","shell.execute_reply":"2021-11-20T11:16:22.800829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}